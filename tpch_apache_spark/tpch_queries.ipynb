{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import glob\r\n",
    "import time\r\n",
    "import sys\r\n",
    "import findspark\r\n",
    "findspark.init()\r\n",
    "findspark.find()\r\n",
    "import pyspark\r\n",
    "findspark.find()\r\n",
    "from pyspark.sql import SparkSession"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "spark = SparkSession \\\r\n",
    "    .builder \\\r\n",
    "    .appName(\"tpch\") \\\r\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/tpch\") \\\r\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/tpch\") \\\r\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\")\\\r\n",
    "    .config(\"spark.executor.memory\", \"2g\")\\\r\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\r\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "customer_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.CUSTOMER\").load()\r\n",
    "lineitem_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.LINEITEM\").load()\r\n",
    "nation_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.NATION\").load()\r\n",
    "region_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.REGION\").load()\r\n",
    "orders_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.ORDERS\").load()\r\n",
    "part_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.PART\").load()\r\n",
    "partsupp_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.PARTSUPP\").load()\r\n",
    "supplier_df = spark.read.format(\"mongo\").option(\"uri\",\"mongodb://127.0.0.1/tpch.SUPPLIER\").load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "customer_df.createOrReplaceTempView(\"customer\")\r\n",
    "lineitem_df.createOrReplaceTempView(\"lineitem\")\r\n",
    "nation_df.createOrReplaceTempView(\"nation\")\r\n",
    "region_df.createOrReplaceTempView(\"region\")\r\n",
    "orders_df.createOrReplaceTempView(\"orders\")\r\n",
    "part_df.createOrReplaceTempView(\"part\")\r\n",
    "partsupp_df.createOrReplaceTempView(\"partsupp\")\r\n",
    "supplier_df.createOrReplaceTempView(\"supplier\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def q1():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    l_returnflag,\r\n",
    "    l_linestatus,\r\n",
    "    sum(l_quantity) as sum_qty,\r\n",
    "    sum(l_extendedprice) as sum_base_price,\r\n",
    "    sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,\r\n",
    "    sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,\r\n",
    "    avg(l_quantity) as avg_qty,\r\n",
    "    avg(l_extendedprice) as avg_price,\r\n",
    "    avg(l_discount) as avg_disc,\r\n",
    "    count(*) as count_order\r\n",
    "from\r\n",
    "    LINEITEM\r\n",
    "where\r\n",
    "    l_shipdate <= date '1998-12-01' - interval '108' day\r\n",
    "group by\r\n",
    "    l_returnflag,\r\n",
    "    l_linestatus\r\n",
    "order by\r\n",
    "    l_returnflag,\r\n",
    "    l_linestatus;\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def q2():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    s_acctbal,\r\n",
    "    s_name,\r\n",
    "    n_name,\r\n",
    "    p_partkey,\r\n",
    "    p_mfgr,\r\n",
    "    s_address,\r\n",
    "    s_phone,\r\n",
    "    s_comment\r\n",
    "from\r\n",
    "    PART,\r\n",
    "    SUPPLIER,\r\n",
    "    PARTSUPP,\r\n",
    "    NATION,\r\n",
    "    REGION\r\n",
    "where\r\n",
    "    p_partkey = ps_partkey\r\n",
    "    and s_suppkey = ps_suppkey\r\n",
    "    and p_size = 30\r\n",
    "    and p_type like '%STEEL'\r\n",
    "    and s_nationkey = n_nationkey\r\n",
    "    and n_regionkey = r_regionkey\r\n",
    "    and r_name = 'ASIA'\r\n",
    "    and ps_supplycost = (\r\n",
    "        select\r\n",
    "            min(ps_supplycost)\r\n",
    "        from\r\n",
    "            PARTSUPP,\r\n",
    "            SUPPLIER,\r\n",
    "            NATION,\r\n",
    "            REGION\r\n",
    "        where\r\n",
    "            p_partkey = ps_partkey\r\n",
    "            and s_suppkey = ps_suppkey\r\n",
    "            and s_nationkey = n_nationkey\r\n",
    "            and n_regionkey = r_regionkey\r\n",
    "            and r_name = 'ASIA'\r\n",
    "    )\r\n",
    "order by\r\n",
    "    s_acctbal desc,\r\n",
    "    n_name,\r\n",
    "    s_name,\r\n",
    "    p_partkey\r\n",
    "limit\r\n",
    "    100;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def q3():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    l_orderkey,\r\n",
    "    sum(l_extendedprice * (1 - l_discount)) as revenue,\r\n",
    "    o_orderdate,\r\n",
    "    o_shippriority\r\n",
    "from\r\n",
    "    CUSTOMER,\r\n",
    "    ORDERS,\r\n",
    "    LINEITEM\r\n",
    "where\r\n",
    "    c_mktsegment = 'AUTOMOBILE'\r\n",
    "    and c_custkey = o_custkey\r\n",
    "    and l_orderkey = o_orderkey\r\n",
    "    and o_orderdate < date '1995-03-13'\r\n",
    "    and l_shipdate > date '1995-03-13'\r\n",
    "group by\r\n",
    "    l_orderkey,\r\n",
    "    o_orderdate,\r\n",
    "    o_shippriority\r\n",
    "order by\r\n",
    "    revenue desc,\r\n",
    "    o_orderdate\r\n",
    "limit\r\n",
    "    10;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def q4():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    o_orderpriority,\r\n",
    "    count(*) as order_count\r\n",
    "from\r\n",
    "    ORDERS\r\n",
    "where\r\n",
    "    o_orderdate >= date '1995-01-01'\r\n",
    "    and o_orderdate < date '1995-01-01' + interval '3' month\r\n",
    "    and exists (\r\n",
    "        select\r\n",
    "            *\r\n",
    "        from\r\n",
    "            LINEITEM\r\n",
    "        where\r\n",
    "            l_orderkey = o_orderkey\r\n",
    "            and l_commitdate < l_receiptdate\r\n",
    "    )\r\n",
    "group by\r\n",
    "    o_orderpriority\r\n",
    "order by\r\n",
    "    o_orderpriority;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def q5():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    n_name,\n",
    "    sum(l_extendedprice * (1 - l_discount)) as revenue\n",
    "from\n",
    "    CUSTOMER,\n",
    "    ORDERS,\n",
    "    LINEITEM,\n",
    "    SUPPLIER,\n",
    "    NATION,\n",
    "    REGION\n",
    "where\n",
    "    c_custkey = o_custkey\n",
    "    and l_orderkey = o_orderkey\n",
    "    and l_suppkey = s_suppkey\n",
    "    and c_nationkey = s_nationkey\n",
    "    and s_nationkey = n_nationkey\n",
    "    and n_regionkey = r_regionkey\n",
    "    and r_name = 'MIDDLE EAST'\n",
    "    and o_orderdate >= date '1994-01-01'\n",
    "    and o_orderdate < date '1994-01-01' + interval '1' year\n",
    "group by\n",
    "    n_name\n",
    "order by\n",
    "    revenue desc;\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def q6():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    sum(l_extendedprice * l_discount) as revenue\n",
    "from\n",
    "    LINEITEM\n",
    "where\n",
    "    l_shipdate >= date '1994-01-01'\n",
    "    and l_shipdate < date '1994-01-01' + interval '1' year\n",
    "    and l_discount between 0.06 - 0.01\n",
    "    and 0.06 + 0.01\n",
    "    and l_quantity < 24;\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def q7():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    supp_nation,\n",
    "    cust_nation,\n",
    "    l_year,\n",
    "    sum(volume) as revenue\n",
    "from\n",
    "    (\n",
    "        select\n",
    "            n1.n_name as supp_nation,\n",
    "            n2.n_name as cust_nation,\n",
    "            extract(\n",
    "                year\n",
    "                from\n",
    "                    l_shipdate\n",
    "            ) as l_year,\n",
    "            l_extendedprice * (1 - l_discount) as volume\n",
    "        from\n",
    "            SUPPLIER,\n",
    "            LINEITEM,\n",
    "            ORDERS,\n",
    "            CUSTOMER,\n",
    "            NATION n1,\n",
    "            NATION n2\n",
    "        where\n",
    "            s_suppkey = l_suppkey\n",
    "            and o_orderkey = l_orderkey\n",
    "            and c_custkey = o_custkey\n",
    "            and s_nationkey = n1.n_nationkey\n",
    "            and c_nationkey = n2.n_nationkey\n",
    "            and (\n",
    "                (\n",
    "                    n1.n_name = 'JAPAN'\n",
    "                    and n2.n_name = 'INDIA'\n",
    "                )\n",
    "                or (\n",
    "                    n1.n_name = 'INDIA'\n",
    "                    and n2.n_name = 'JAPAN'\n",
    "                )\n",
    "            )\n",
    "            and l_shipdate between date '1995-01-01'\n",
    "            and date '1996-12-31'\n",
    "    ) as shipping\n",
    "group by\n",
    "    supp_nation,\n",
    "    cust_nation,\n",
    "    l_year\n",
    "order by\n",
    "    supp_nation,\n",
    "    cust_nation,\n",
    "    l_year;\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def q8():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    o_year,\r\n",
    "    sum(\r\n",
    "        case\r\n",
    "            when nation = 'INDIA' then volume\r\n",
    "            else 0\r\n",
    "        end\r\n",
    "    ) / sum(volume) as mkt_share\r\n",
    "from\r\n",
    "    (\r\n",
    "        select\r\n",
    "            extract(\r\n",
    "                year\r\n",
    "                from\r\n",
    "                    o_orderdate\r\n",
    "            ) as o_year,\r\n",
    "            l_extendedprice * (1 - l_discount) as volume,\r\n",
    "            n2.n_name as nation\r\n",
    "        from\r\n",
    "            PART,\r\n",
    "            SUPPLIER,\r\n",
    "            LINEITEM,\r\n",
    "            ORDERS,\r\n",
    "            CUSTOMER,\r\n",
    "            NATION n1,\r\n",
    "            NATION n2,\r\n",
    "            REGION\r\n",
    "        where\r\n",
    "            p_partkey = l_partkey\r\n",
    "            and s_suppkey = l_suppkey\r\n",
    "            and l_orderkey = o_orderkey\r\n",
    "            and o_custkey = c_custkey\r\n",
    "            and c_nationkey = n1.n_nationkey\r\n",
    "            and n1.n_regionkey = r_regionkey\r\n",
    "            and r_name = 'ASIA'\r\n",
    "            and s_nationkey = n2.n_nationkey\r\n",
    "            and o_orderdate between date '1995-01-01'\r\n",
    "            and date '1996-12-31'\r\n",
    "            and p_type = 'SMALL PLATED COPPER'\r\n",
    "    ) as all_nations\r\n",
    "group by\r\n",
    "    o_year\r\n",
    "order by\r\n",
    "    o_year;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def q9():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    nation,\r\n",
    "    o_year,\r\n",
    "    sum(amount) as sum_profit\r\n",
    "from\r\n",
    "    (\r\n",
    "        select\r\n",
    "            n_name as nation,\r\n",
    "            extract(\r\n",
    "                year\r\n",
    "                from\r\n",
    "                    o_orderdate\r\n",
    "            ) as o_year,\r\n",
    "            l_extendedprice * (1 - l_discount) - ps_supplycost * l_quantity as amount\r\n",
    "        from\r\n",
    "            PART,\r\n",
    "            SUPPLIER,\r\n",
    "            LINEITEM,\r\n",
    "            PARTSUPP,\r\n",
    "            ORDERS,\r\n",
    "            NATION\r\n",
    "        where\r\n",
    "            s_suppkey = l_suppkey\r\n",
    "            and ps_suppkey = l_suppkey\r\n",
    "            and ps_partkey = l_partkey\r\n",
    "            and p_partkey = l_partkey\r\n",
    "            and o_orderkey = l_orderkey\r\n",
    "            and s_nationkey = n_nationkey\r\n",
    "            and p_name like '%dim%'\r\n",
    "    ) as profit\r\n",
    "group by\r\n",
    "    nation,\r\n",
    "    o_year\r\n",
    "order by\r\n",
    "    nation,\r\n",
    "    o_year desc;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def q10():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    sum(l_extendedprice * (1 - l_discount)) as revenue,\n",
    "    c_acctbal,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_phone,\n",
    "    c_comment\n",
    "from\n",
    "    CUSTOMER,\n",
    "    ORDERS,\n",
    "    LINEITEM,\n",
    "    NATION\n",
    "where\n",
    "    c_custkey = o_custkey\n",
    "    and l_orderkey = o_orderkey\n",
    "    and o_orderdate >= date '1993-08-01'\n",
    "    and o_orderdate < date '1993-08-01' + interval '3' month\n",
    "    and l_returnflag = 'R'\n",
    "    and c_nationkey = n_nationkey\n",
    "group by\n",
    "    c_custkey,\n",
    "    c_name,\n",
    "    c_acctbal,\n",
    "    c_phone,\n",
    "    n_name,\n",
    "    c_address,\n",
    "    c_comment\n",
    "order by\n",
    "    revenue desc\n",
    "limit\n",
    "    20;\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def q11():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    ps_partkey,\n",
    "    sum(ps_supplycost * ps_availqty) as value\n",
    "from\n",
    "    PARTSUPP,\n",
    "    SUPPLIER,\n",
    "    NATION\n",
    "where\n",
    "    ps_suppkey = s_suppkey\n",
    "    and s_nationkey = n_nationkey\n",
    "    and n_name = 'MOZAMBIQUE'\n",
    "group by\n",
    "    ps_partkey\n",
    "having\n",
    "    sum(ps_supplycost * ps_availqty) > (\n",
    "        select\n",
    "            sum(ps_supplycost * ps_availqty) * 0.0001000000\n",
    "        from\n",
    "            PARTSUPP,\n",
    "            SUPPLIER,\n",
    "            NATION\n",
    "        where\n",
    "            ps_suppkey = s_suppkey\n",
    "            and s_nationkey = n_nationkey\n",
    "            and n_name = 'MOZAMBIQUE'\n",
    "    )\n",
    "order by\n",
    "    value desc;\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def q12():\r\n",
    "        query = \"\"\"\r\n",
    "select l_shipmode,\r\n",
    "sum(\r\n",
    "    case\r\n",
    "        when o_orderpriority = '1-URGENT'\r\n",
    "        or o_orderpriority = '2-HIGH' then 1\r\n",
    "        else 0\r\n",
    "    end\r\n",
    ") as high_line_count,\r\n",
    "sum(\r\n",
    "    case\r\n",
    "        when o_orderpriority <> '1-URGENT'\r\n",
    "        and o_orderpriority <> '2-HIGH' then 1\r\n",
    "        else 0\r\n",
    "    end\r\n",
    ") as low_line_count\r\n",
    "from\r\n",
    "    ORDERS,\r\n",
    "    LINEITEM\r\n",
    "where\r\n",
    "    o_orderkey = l_orderkey\r\n",
    "    and l_shipmode in ('RAIL', 'FOB')\r\n",
    "    and l_commitdate < l_receiptdate\r\n",
    "    and l_shipdate < l_commitdate\r\n",
    "    and l_receiptdate >= date '1997-01-01'\r\n",
    "    and l_receiptdate < date '1997-01-01' + interval '1' year\r\n",
    "group by\r\n",
    "    l_shipmode\r\n",
    "order by\r\n",
    "    l_shipmode;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def q13():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    c_count,\r\n",
    "    count(*) as custdist\r\n",
    "from\r\n",
    "    (\r\n",
    "        select\r\n",
    "            c_custkey,\r\n",
    "            count(o_orderkey) as c_count\r\n",
    "        from\r\n",
    "            CUSTOMER\r\n",
    "            left outer join ORDERS on c_custkey = o_custkey\r\n",
    "            and o_comment not like '%pending%deposits%'\r\n",
    "        group by\r\n",
    "            c_custkey\r\n",
    "    ) c_orders\r\n",
    "group by\r\n",
    "    c_count\r\n",
    "order by\r\n",
    "    custdist desc,\r\n",
    "    c_count desc;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def q14():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    100.00 * sum(\r\n",
    "        case\r\n",
    "            when p_type like 'PROMO%' then l_extendedprice * (1 - l_discount)\r\n",
    "            else 0\r\n",
    "        end\r\n",
    "    ) / sum(l_extendedprice * (1 - l_discount)) as promo_revenue\r\n",
    "from\r\n",
    "    LINEITEM,\r\n",
    "    PART\r\n",
    "where\r\n",
    "    l_partkey = p_partkey\r\n",
    "    and l_shipdate >= date '1996-12-01'\r\n",
    "    and l_shipdate < date '1996-12-01' + interval '1' month;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def q15():\r\n",
    "        query = \"\"\"\r\n",
    "with revenue0 as\r\n",
    " (select\r\n",
    " l_suppkey as supplier_no,\r\n",
    " sum(l_extendedprice * (1 - l_discount)) as total_revenue\r\n",
    " from\r\n",
    " lineitem\r\n",
    " where\r\n",
    " l_shipdate >= date '1997-07-01'\r\n",
    " and l_shipdate < date '1997-07-01' + interval '3' month\r\n",
    " group by\r\n",
    " l_suppkey)\r\n",
    "\r\n",
    " select\r\n",
    " s_suppkey,\r\n",
    " s_name,\r\n",
    " s_address,\r\n",
    " s_phone,\r\n",
    " total_revenue\r\n",
    " from\r\n",
    " supplier,\r\n",
    " revenue0\r\n",
    " where\r\n",
    " s_suppkey = supplier_no\r\n",
    " and total_revenue = (\r\n",
    " select\r\n",
    " max(total_revenue)\r\n",
    " from\r\n",
    " revenue0\r\n",
    " )\r\n",
    " order by\r\n",
    " s_suppkey\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def q16():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    p_brand,\r\n",
    "    p_type,\r\n",
    "    p_size,\r\n",
    "    count(distinct ps_suppkey) as supplier_cnt\r\n",
    "from\r\n",
    "    PARTSUPP,\r\n",
    "    PART\r\n",
    "where\r\n",
    "    p_partkey = ps_partkey\r\n",
    "    and p_brand <> 'Brand#34'\r\n",
    "    and p_type not like 'LARGE BRUSHED%'\r\n",
    "    and p_size in (48, 19, 12, 4, 41, 7, 21, 39)\r\n",
    "    and ps_suppkey not in (\r\n",
    "        select\r\n",
    "            s_suppkey\r\n",
    "        from\r\n",
    "            SUPPLIER\r\n",
    "        where\r\n",
    "            s_comment like '%Customer%Complaints%'\r\n",
    "    )\r\n",
    "group by\r\n",
    "    p_brand,\r\n",
    "    p_type,\r\n",
    "    p_size\r\n",
    "order by\r\n",
    "    supplier_cnt desc,\r\n",
    "    p_brand,\r\n",
    "    p_type,\r\n",
    "    p_size;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def q17():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    sum(l_extendedprice) / 7.0 as avg_yearly\n",
    "from\n",
    "    LINEITEM,\n",
    "    PART\n",
    "where\n",
    "    p_partkey = l_partkey\n",
    "    and p_brand = 'Brand#44'\n",
    "    and p_container = 'WRAP PKG'\n",
    "    and l_quantity < (\n",
    "        select\n",
    "            0.2 * avg(l_quantity)\n",
    "        from\n",
    "            LINEITEM\n",
    "        where\n",
    "            l_partkey = p_partkey\n",
    "    );\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def q18():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    c_name,\r\n",
    "    c_custkey,\r\n",
    "    o_orderkey,\r\n",
    "    o_orderdate,\r\n",
    "    o_totalprice,\r\n",
    "    sum(l_quantity)\r\n",
    "from\r\n",
    "    CUSTOMER,\r\n",
    "    ORDERS,\r\n",
    "    LINEITEM\r\n",
    "where\r\n",
    "    o_orderkey in (\r\n",
    "        select\r\n",
    "            l_orderkey\r\n",
    "        from\r\n",
    "            LINEITEM\r\n",
    "        group by\r\n",
    "            l_orderkey\r\n",
    "        having\r\n",
    "            sum(l_quantity) > 314\r\n",
    "    )\r\n",
    "    and c_custkey = o_custkey\r\n",
    "    and o_orderkey = l_orderkey\r\n",
    "group by\r\n",
    "    c_name,\r\n",
    "    c_custkey,\r\n",
    "    o_orderkey,\r\n",
    "    o_orderdate,\r\n",
    "    o_totalprice\r\n",
    "order by\r\n",
    "    o_totalprice desc,\r\n",
    "    o_orderdate\r\n",
    "limit\r\n",
    "    100;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def q19():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    sum(l_extendedprice * (1 - l_discount)) as revenue\r\n",
    "from\r\n",
    "    LINEITEM,\r\n",
    "    PART\r\n",
    "where\r\n",
    "    (\r\n",
    "        p_partkey = l_partkey\r\n",
    "        and p_brand = 'Brand#52'\r\n",
    "        and p_container in ('SM CASE', 'SM BOX', 'SM PACK', 'SM PKG')\r\n",
    "        and l_quantity >= 4\r\n",
    "        and l_quantity <= 4 + 10\r\n",
    "        and p_size between 1\r\n",
    "        and 5\r\n",
    "        and l_shipmode in ('AIR', 'AIR REG')\r\n",
    "        and l_shipinstruct = 'DELIVER IN PERSON'\r\n",
    "    )\r\n",
    "    or (\r\n",
    "        p_partkey = l_partkey\r\n",
    "        and p_brand = 'Brand#11'\r\n",
    "        and p_container in ('MED BAG', 'MED BOX', 'MED PKG', 'MED PACK')\r\n",
    "        and l_quantity >= 18\r\n",
    "        and l_quantity <= 18 + 10\r\n",
    "        and p_size between 1\r\n",
    "        and 10\r\n",
    "        and l_shipmode in ('AIR', 'AIR REG')\r\n",
    "        and l_shipinstruct = 'DELIVER IN PERSON'\r\n",
    "    )\r\n",
    "    or (\r\n",
    "        p_partkey = l_partkey\r\n",
    "        and p_brand = 'Brand#51'\r\n",
    "        and p_container in ('LG CASE', 'LG BOX', 'LG PACK', 'LG PKG')\r\n",
    "        and l_quantity >= 29\r\n",
    "        and l_quantity <= 29 + 10\r\n",
    "        and p_size between 1\r\n",
    "        and 15\r\n",
    "        and l_shipmode in ('AIR', 'AIR REG')\r\n",
    "        and l_shipinstruct = 'DELIVER IN PERSON'\r\n",
    "    );\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def q20():\n",
    "        query = \"\"\"\n",
    "select\n",
    "    s_name,\n",
    "    s_address\n",
    "from\n",
    "    SUPPLIER,\n",
    "    NATION\n",
    "where\n",
    "    s_suppkey in (\n",
    "        select\n",
    "            ps_suppkey\n",
    "        from\n",
    "            PARTSUPP\n",
    "        where\n",
    "            ps_partkey in (\n",
    "                select\n",
    "                    p_partkey\n",
    "                from\n",
    "                    PART\n",
    "                where\n",
    "                    p_name like 'green%'\n",
    "            )\n",
    "            and ps_availqty > (\n",
    "                select\n",
    "                    0.5 * sum(l_quantity)\n",
    "                from\n",
    "                    LINEITEM\n",
    "                where\n",
    "                    l_partkey = ps_partkey\n",
    "                    and l_suppkey = ps_suppkey\n",
    "                    and l_shipdate >= date '1993-01-01'\n",
    "                    and l_shipdate < date '1993-01-01' + interval '1' year\n",
    "            )\n",
    "    )\n",
    "    and s_nationkey = n_nationkey\n",
    "    and n_name = 'ALGERIA'\n",
    "order by\n",
    "    s_name;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def q21():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    s_name,\r\n",
    "    count(*) as numwait\r\n",
    "from\r\n",
    "    SUPPLIER,\r\n",
    "    LINEITEM l1,\r\n",
    "    ORDERS,\r\n",
    "    NATION\r\n",
    "where\r\n",
    "    s_suppkey = l1.l_suppkey\r\n",
    "    and o_orderkey = l1.l_orderkey\r\n",
    "    and o_orderstatus = 'F'\r\n",
    "    and l1.l_receiptdate > l1.l_commitdate\r\n",
    "    and exists (\r\n",
    "        select\r\n",
    "            *\r\n",
    "        from\r\n",
    "            LINEITEM l2\r\n",
    "        where\r\n",
    "            l2.l_orderkey = l1.l_orderkey\r\n",
    "            and l2.l_suppkey <> l1.l_suppkey\r\n",
    "    )\r\n",
    "    and not exists (\r\n",
    "        select\r\n",
    "            *\r\n",
    "        from\r\n",
    "            LINEITEM l3\r\n",
    "        where\r\n",
    "            l3.l_orderkey = l1.l_orderkey\r\n",
    "            and l3.l_suppkey <> l1.l_suppkey\r\n",
    "            and l3.l_receiptdate > l3.l_commitdate\r\n",
    "    )\r\n",
    "    and s_nationkey = n_nationkey\r\n",
    "    and n_name = 'EGYPT'\r\n",
    "group by\r\n",
    "    s_name\r\n",
    "order by\r\n",
    "    numwait desc,\r\n",
    "    s_name\r\n",
    "limit\r\n",
    "    100;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def q22():\r\n",
    "        query = \"\"\"\r\n",
    "select\r\n",
    "    cntrycode,\r\n",
    "    count(*) as numcust,\r\n",
    "    sum(c_acctbal) as totacctbal\r\n",
    "from\r\n",
    "    (\r\n",
    "        select\r\n",
    "            substring(\r\n",
    "                c_phone\r\n",
    "                from\r\n",
    "                    1 for 2\r\n",
    "            ) as cntrycode,\r\n",
    "            c_acctbal\r\n",
    "        from\r\n",
    "            CUSTOMER\r\n",
    "        where\r\n",
    "            substring(\r\n",
    "                c_phone\r\n",
    "                from\r\n",
    "                    1 for 2\r\n",
    "            ) in ('20', '40', '22', '30', '39', '42', '21')\r\n",
    "            and c_acctbal > (\r\n",
    "                select\r\n",
    "                    avg(c_acctbal)\r\n",
    "                from\r\n",
    "                    CUSTOMER\r\n",
    "                where\r\n",
    "                    c_acctbal > 0.00\r\n",
    "                    and substring(\r\n",
    "                        c_phone\r\n",
    "                        from\r\n",
    "                            1 for 2\r\n",
    "                    ) in ('20', '40', '22', '30', '39', '42', '21')\r\n",
    "            )\r\n",
    "            and not exists (\r\n",
    "                select\r\n",
    "                    *\r\n",
    "                from\r\n",
    "                    ORDERS\r\n",
    "                where\r\n",
    "                    o_custkey = c_custkey\r\n",
    "            )\r\n",
    "    ) as custsale\r\n",
    "group by\r\n",
    "    cntrycode\r\n",
    "order by\r\n",
    "    cntrycode;\r\n",
    "\r\n",
    "\r\n",
    "        \"\"\"\r\n",
    "        spark.sql(query).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def execute_queries(q):\r\n",
    "    start_time = end_time = time.time()\r\n",
    "    query = 'q'+str(q)+\"()\"\r\n",
    "    eval(query)\r\n",
    "    end_time = time.time()\r\n",
    "    print(\"Time taken to execute query %s : %.2f s\" %(q,(end_time - start_time)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "n = len(sys.argv)\r\n",
    "if n > 0:\r\n",
    "    execute_queries(sys.argv[1])\r\n",
    "else:\r\n",
    "    print(\"Mention Query No.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------+-------+\n",
      "|            s_name|numwait|\n",
      "+------------------+-------+\n",
      "|Supplier#000000246|     15|\n",
      "|Supplier#000000655|     15|\n",
      "|Supplier#000000599|     14|\n",
      "|Supplier#000000208|     13|\n",
      "|Supplier#000000227|     13|\n",
      "|Supplier#000000301|     13|\n",
      "|Supplier#000000618|     13|\n",
      "|Supplier#000000898|     13|\n",
      "|Supplier#000000094|     12|\n",
      "|Supplier#000000343|     12|\n",
      "|Supplier#000000856|     12|\n",
      "|Supplier#000000159|     11|\n",
      "|Supplier#000000664|     11|\n",
      "|Supplier#000000022|     10|\n",
      "|Supplier#000000038|     10|\n",
      "|Supplier#000000105|     10|\n",
      "|Supplier#000000111|     10|\n",
      "|Supplier#000000502|     10|\n",
      "|Supplier#000000938|     10|\n",
      "|Supplier#000000069|      9|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken to execute query 21 : 13.35\n",
      "+---------+-------+-----------------+\n",
      "|cntrycode|numcust|       totacctbal|\n",
      "+---------+-------+-----------------+\n",
      "|       20|     91|666158.0999999997|\n",
      "|       21|    101|760953.5499999999|\n",
      "|       22|    106|759804.8099999996|\n",
      "|       30|     87|646748.0199999999|\n",
      "+---------+-------+-----------------+\n",
      "\n",
      "Time taken to execute query 22 : 2.08\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "spark.stop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1207, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1033, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1211, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n",
      "/opt/spark/python/pyspark/context.py:460: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n",
      "  warnings.warn(\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38009)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:38009)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5c6b4d5d9db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;31m# We should clean the default session up. See SPARK-23228.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclearDefaultSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclearActiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiatedSession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUserHelpAutoCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         answer = self._gateway_client.send_command(\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:38009)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}